# command+Alt+I or ctrl+shift+I
# pip install requests
# pip install beautifulsoup4
# pip install html5lib
# pip install -U selenium
#ctrl+shift+ -  : split cell

# https://www.bmwusa.com/vehicles/3-series/sedan/overview.html
# User-agent: *
# Disallow: /api
# Disallow: /search-results.html
# Disallow: /errors/
# Disallow: /errors.html
# Disallow: /cms.html
# Sitemap: https://www.bmwusa.com/sitemap.xml




import requests
#from selenium import webdriver   #dynamic
from bs4 import BeautifulSoup
import pandas as pd
import re
from datetime import datetime


URL = "https://www.bmwusa.com/vehicles/3-series/sedan/overview.html/"
page = requests.get(URL)
print(page.text)


soup = BeautifulSoup(page.content, "html.parser")



# <div id="ResultsContainer">
#   <!-- all the job listings -->
# </div>
#results = soup.find(id="price-label label-2")

# results = soup.find(class_="price-value label-2")
# print(results.prettify())





job_elements = soup.find_all(class_="price-value label-2")
job_elements

# python_jobs = results.find_all("h2", string=lambda text: "python" in text.lower())
# python_job_elements = [h2_element.parent.parent.parent for h2_element in python_jobs]


job_elements[0].find()



prices=[]
for job_element in job_elements:
    price_element = str(job_element)
    #print(price_element)
    regex = re.compile('\$..,...')
    match=re.findall(regex, price_element)
    print(match)
    # prices.append(match)
    prices.extend(match)
    # company_element = job_element.find("h3", class_="company")
    # location_element = job_element.find("p", class_="location")
    # print(price_element.text.strip())
prices_list=list(set(prices))
prices_list



# or selenium
# driver = webdriver.Chrome("/usr/lib/chromium-browser/chromedriver") # webdriver.Safari()
# driver.get("url")


d={'date': [datetime.now()], 'price_series3_new_USD': [int(min(prices_list)[1:].replace(',', ''))]}
df=pd.DataFrame(d)
df


df.to_csv('series3_prices.csv', mode='a', index=False, header=False)

